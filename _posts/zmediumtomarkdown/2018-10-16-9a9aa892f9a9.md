---
title: Vision 初探 — APP 頭像上傳 自動識別人臉裁圖 (Swift)
author: ZhgChgLi
date: 2018-10-16T16:01:24.511+0000
last_modified_at: 2021-02-24T01:27:03.600+0000
categories: ZRealm Dev.
tags: [swift,machine-learning,facedetection,ios,ios-app-development]
description: Vision 實戰應用
image:
  path: assets/9a9aa892f9a9/1*c-ioRH_Z2nMYRxSbuBD71A.png
render_with_liquid: false
---

### Vision 初探 — APP 頭像上傳 自動識別人臉裁圖 \(Swift\)

Vision 實戰應用
#### 一樣不多說，先上一張成品圖：


![優化前 V\.S 優化後 — [結婚吧APP](https://itunes.apple.com/tw/app/%E7%B5%90%E5%A9%9A%E5%90%A7-%E4%B8%8D%E6%89%BE%E6%9C%80%E8%B2%B4-%E5%8F%AA%E6%89%BE%E6%9C%80%E5%B0%8D/id1356057329?ls=1&mt=8){:target="_blank"}](/assets/9a9aa892f9a9/1*c-ioRH_Z2nMYRxSbuBD71A.png)

優化前 V\.S 優化後 — [結婚吧APP](https://itunes.apple.com/tw/app/%E7%B5%90%E5%A9%9A%E5%90%A7-%E4%B8%8D%E6%89%BE%E6%9C%80%E8%B2%B4-%E5%8F%AA%E6%89%BE%E6%9C%80%E5%B0%8D/id1356057329?ls=1&mt=8){:target="_blank"}

前陣子iOS 12發佈更新，注意到新開放的CoreML 機器學習框架；覺得挺有趣的，就開始構想如果想用在當前的產品上能放在哪裡？


> **CoreML嚐鮮文章現已發佈： [使用機器學習自動預測文章分類，連模型也自己訓練](../793bf2cdda0f/)** 





CoreML提供文字、圖像的機器學習模型訓練及引用到APP裡的接口，我原先的想法是，使用CoreML來做到人臉識別，解決APP中有裁圖的項目頭或臉被卡掉的問題，如上圖左所示，若人臉出現在周圍則很容易因為縮放＋裁圖造成臉不完整．

經過網路搜尋一番後才發現我學識短淺，這個功能在iOS 11就已發佈：「Vision」框架，支援文字偵測、人臉偵測、圖像比對、QRCODE偵測、物件追蹤…功能

這邊使用的就是其中的人臉偵測項目，經優化後如右圖所示；找到人臉並以此為中心裁圖．
### 實戰開始：
#### 首先我們先做能標記人臉位置的功能，初步認識一下Vision怎麼用


![Demo APP](/assets/9a9aa892f9a9/1*cpGgpXsBhuiJoZI03WAGUw.png)

Demo APP

完成圖如上所示，能標記出照片中人臉的位置

p\.s 僅能標記「人臉」，整個頭包含頭髮並不行😅

這塊程式主要分為兩部分，第一部分要解決 圖片原尺寸縮放放入 ImageView時會留白的狀況；簡單來說我們要的是Image的Size多大，ImageView的Size就有多大，若直接放入圖片會造成如下走位情形


![](/assets/9a9aa892f9a9/1*Mb70Ed6pALO-8sllCpb7Qg.png)


你可能會想說直接改ContentMode變成fill、fit、redraw，但就會變形或圖片被卡掉
